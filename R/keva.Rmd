---
title: An attempt at optimal allocation minimizing optorunity costs
author: Daniel R. Williams ^[Director of Quality Control, Greenstreet Growers, Lothian,
  MD] ^[PhD Candidate, Dept. of Ag. & Crop Science, Ohio State University, Columbus,  Ohio]
date: 26 Aug 2024
output:
  html_notebook: default
---

# To Do

- [ ] I/O functions
  - [ ] where/how best to pull data? `rest` or an api?
  - [ ] how best to manage data? local storage of downloaded data?
- [ ] Alogrithms
  - [ ] retrieve plan from previous projects
  - [ ] retrieve plan from Tim

```{r setup, echo=FALSE, error=TRUE, message=TRUE, warning=TRUE, include=FALSE}
# this block loads required packages and some custom functions. 
cran_pacs <- c("tidyverse","writexl","fs","stringr","rlang","magrittr","stats","foreach", "doParallel", "parallel", "fs", "janitor", "stringr","lubridate","forcats", "purrr","multidplyr", "curl", "units", "readxl", "datawizard", "sjmisc", "quantmod", "xts", "zoo", "TTR", "tidyquant") #, "rvest", "chromote","httr2", "forecast"
dev_pacs <- c("eddelbuettel/td") 
bioc_pacs <- c()
py_pacs <- c()

# install installers
if(length(find.package("pak", quiet = TRUE))==0) install.packages("pak")
if(length(find.package("librarian", quiet = TRUE))==0) pak::pak("librarian")
installer_pacs <- Filter(librarian::check_installed, c(if (length(bioc_pacs) > 0) "BiocManager", if (length(py_pacs) > 0) "reticulate"))
if (length(installer_pacs) > 0) pak::pak(installer_pacs, upgrade = TRUE)

# install and load R pacs
r_pacs <- c(cran_pacs,dev_pacs,bioc_pacs) |> unique()
if (length(r_pacs) > 0) {
  pak::pak(r_pacs, upgrade = FALSE, ask = FALSE)
  librarian::shelf(r_pacs)
}

# install python packs
if (length(py_pacs)>0) {
  if (!reticulate::py_available(initialize = TRUE)) reticulate::install_python()
  if (reticulate::py_available(initialize = TRUE)) reticulate::py_install(py_pacs)
}

## register cores for foreach/doParallel
n_cores <- case_match(.Platform$OS.type,
                      "windows" ~ (parallel::detectCores() * 5/9) |> round(),
                      .default = parallel::detectCores() - 1)
# registerDoParallel(cores=n_cores)
# stopImplicitCluster()

# doParallel cluster
if(!is_null(getDefaultCluster())) stopCluster(getDefaultCluster())
makeCluster(n_cores) |> setDefaultCluster()
registerDoParallel(getDefaultCluster())

# dplyr cluster
if(exists("dCluster")) rm(dCluster)
dCluster <- new_cluster(n_cores)
cluster_library_quiety <- purrr::quietly(cluster_library)
# cluster_library_quiety(dCluster, loadedNamespaces())
cluster_library_quiety(dCluster, librarian::check_attached())
```

```{r utils}

round_any = function(x, accuracy, f=round){f(x/accuracy) * accuracy}

# read_xlsxs <- function(path, ...) foreach(i=1:length(path), .combine = add_case, .packages = "readxl") %do% read_xlsx(path[i],...)
read_excels <- function(path, trim_at_blank_line = TRUE, ...) {
  foreach(i=1:length(path), .combine = "rbind", .verbose = F, .errorhandling = "pass") %do% {
    if(trim_at_blank_line) readxl::read_excel(path[i],...) |> filter(dplyr::cumall(!dplyr::if_all(dplyr::everything(), is.na)))
    else readxl::read_excel(path[i],...)
  }
}

lastTradingClose <- function(dt = now()) {
  dt %<>% with_tz("America/New_York")
  h <- dt |> hour()
  beforeClosePenalty <- if_else(h < 16L, dhours(24-16+h), dhours(-16+h))
  dt <- dt - beforeClosePenalty
  wday <- dt |> wday(week_start = 1)
  weekendPenalty <- if_else(wday > 5L, ddays(wday - 5L), ddays(0))
  dt <- dt - weekendPenalty
  dt |> update(hours = 16L, minutes = 0L, seconds = 0L, week_start = 1)
}

nextTradingClose <- function(dt = now()) {
  dt %<>% with_tz("America/New_York")
  h <- dt |> hour()
  beforeCloseBoost <- if_else(h < 16L, dhours(16-h), dhours(24+16-h))
  dt <- dt + beforeCloseBoost
  wday <- dt |> wday(week_start = 1)
  weekendBoost <- if_else(wday > 5L, ddays(8L - wday), ddays(0))
  dt <- dt + weekendBoost
  dt |> update(hours = 16L, minutes = 0L, seconds = 0L, week_start = 1)
}

## from a curl http download, turn the headers list into a tibble
http_headers_to_columns_single <- function(headers_line) {
  headers_line |>
    str_squish() |>
    # str_split("(?<=HTTP/\\d\\.?\\d?[:space:])|(:[:space:])") |> 
    str_split("((?<=HTTP)/)|(:[:space:])") |> 
    list_transpose() |> 
    as.data.frame(col.names = c("name","value")) |> 
    pivot_wider(names_from = name)
}
# the vectorized version
http_headers_to_columns <- function(headers) {headers |> sapply(http_headers_to_columns_single, simplify = F) |> list_rbind()}

# http_headers_to_columns(download_details$headers[1:3])
# http_headers_to_columns_single(download_details$headers[[1]])

```

```{r paths}

data_path <- "Dropbox (Personal)/Projects/investing" |> fs::path_home()
hist_path <- "Dropbox (Personal)/Projects/investing/historic data" |> fs::path_home()

```


```{r currentdata}

# install_unit(c("USD", "dollar"))


# "https://digital.fidelity.com/ftgw/digital/portfolio/positions"

# account_nums <-  path(data_path,"fidelity_accountnums.tsv") |> 
#   read_csv(show_col_types = FALSE) |>
#   pull(`fidelity internal account number`)

positions <- data_path |> 
  dir_ls(regexp = "/Portfolio_Positions_.*\\.csv$") |>
  as_tibble_col() |>
  mutate(date = value |> str_extract(pattern = "(?<=/Portfolio_Positions_).*(?=\\.csv$)") |> mdy()) |>
  slice_max(date) |>
  pull(1) |>
  read_csv(show_col_types = FALSE) |>
  filter(!is.na(Symbol),
         !str_detect(Symbol, "Pending")) |>
  mutate(across(`Last Price`:`Average Cost Basis`,\(x) str_remove_all(x,"[\\+$%]*") |> as.numeric()),
         # across(contains("Percent"),\(x) x/100),
         across(contains("Percent"),\(x) set_units(x,"%")),
         # across(where(is.numeric)&!contains("Percent"),\(x) as_units(x, "USD")),
         Symbol = Symbol |> str_extract("[:alnum:]*"),
         across(c(`Account Number`, `Symbol`, `Type`), as.factor))


targets <- data_path |> 
  path("fidelity_targets_20240803.tsv") |> 
  read_tsv(show_col_types = FALSE) |>
  mutate(across(c(`Symbol`), as.factor))

accounts <- positions |> 
  group_by(`Account Number`, `Account Name`) |>
  summarise(`Current Value` = sum(`Current Value`))

```


```{r positionsScrape, eval = FALSE}

login_url <- "https://digital.fidelity.com/prgw/digital/login/full-page"
portfolio_url <- "https://digital.fidelity.com/ftgw/digital/portfolio/positions"


```



```{r downloadhistoricdata}

# "https://query1.finance.yahoo.com/v7/finance/download/FAMRX?period1=938179800&period2=1723135605&interval=1d&events=history&includeAdjustedClose=true"
# symbols <- c(targets$Symbol, positions$Symbol) |> unique() |> keep(\(x) !str_equal(x,"SPAXX"))

baseURL <- "https://query1.finance.yahoo.com/v7/finance/download/"
start_date <- "01-01-2010" |> dmy() |> as_datetime() |> as.integer()
end_date <- now() |> round_date() |> as.integer()
query <- str_c("?period1=",start_date,"&period2=",end_date,"&interval=1d&events=history&includeAdjustedClose=true")

mutualFund_symbols <- data_path |> 
  dir_ls(regexp = "[\\/]Download_Results.*xlsx$") |> as.character() |>
  read_excels(col_types = "text") |>
  filter(!sjmisc::is_empty(`YTD (Daily)`),
         `Morningstar- Overall` |> str_starts("5")) |>
  distinct() |>
  mutate(Symbol = str_extract(Name, "(?<=\\()[:upper:]*(?=\\))"), .before = 1) |>
  select("Symbol")

other_symbols <- data_path |> 
  dir_ls(regexp = "[\\/]screener_results.*xls$") |>
  read_excels(col_types = "text") |>
  filter(!sjmisc::is_empty(`Market Price`)) |>
  distinct() |>
  # mutate(Symbol = str_extract(Name, "(?<=\\()[:upper:]*(?=\\))"), .before = 1) |>
  select("Symbol")

# test <- data_path |>
#   dir_ls(regexp = "[\\/]screener_results.*xls$") |>
#   first() |>
#   read_excels(col_types = "text") |>
#   filter(cumall(!if_all(everything(), \(x) is.na(x))))


manual_symbols = c("NFTY") |> 
  as_tibble_col("Symbol")

download_paramaters <- add_row(targets |> select(Symbol), positions |> select(Symbol)) |>
  add_row(manual_symbols) |>
  add_row(mutualFund_symbols) |>
  # add_row(other_symbols) |> # reducing the computational burden for now
  distinct() |>
  filter(!str_equal(Symbol,"SPAXX")) |>
  mutate(url_query = str_c(baseURL, Symbol |> str_to_lower(),query),
         file_dest = path(hist_path, Symbol |> str_c(".csv")),
         file_exists = file_dest |> file_exists(),
         file_dest |> file_info(),
         file_age = interval(modification_time, now()) |> as.duration())


## This mess downloads data that needs updated. AND if any files fail, it re-tries with wait times between the attempts. 
slow_multi_download <- slowly(multi_download, rate_backoff(pause_base = 3, max_times = 3))
download_details <- download_paramaters |>
  # filter((!file_exists) | (file_age > dhours(8)))
  filter((!file_exists) | (modification_time < lastTradingClose() + dhours(4)) | ((modification_time < lastTradingClose()) & (file_age > dminutes(10))) | (size <= fs_bytes("1K")))
if(nrow(download_details) |> as.logical()) {
    download_details %<>% mutate(slow_multi_download(url_query, file_dest))
    download_details %<>% mutate(headers |> http_headers_to_columns())
  # Retry with wait times
  errors <- download_details |> filter(!str_detect(`HTTP`, "(2[:number:]{2})"))
  while(errors |> nrow() > 0) {
    message(str_c("HTTP/",errors$HTTP |> unique())) # information about the problem
    errors <- errors |> mutate(slow_multi_download(url_query, file_dest))
    errors <- errors |> mutate(headers |> http_headers_to_columns())
    download_details <- rows_upsert(download_details, errors)
    errors <- errors |> filter(!str_detect(`HTTP`, "(2[:number:]{2})"))
  }
  download_paramaters %<>% left_join(download_details)
  }


# testing new twelve data api because Yahoo Finance seems to be blocking me




```

```{r calctradesfun}
calc_trades <- function(positions, targets, cash_reserve = 0.05, max_change = 0.1, min_change = 0.001, sell_buffer = 0.05, transfer = 0) {
  
  # joined <- full_join(positions,targets)
  
  joined <- targets |>
    arrange(rank) |>
    mutate(series = sapply(0:(n()-1),\(x) (1-n()^(-1))^x), 
           targ_prop = series/sum(series) * (1-cash_reserve)) |>
    add_case(Symbol = "SPAXX", targ_prop = cash_reserve) |>
    full_join(positions) |>
    mutate(across(where(is.numeric),\(x) if_else(is.na(x),0,x))) |>
    mutate(value = value + if_else(str_equal(Symbol,"SPAXX"), transfer, 0),
           targ_pos = sum(value) * targ_prop,
           targ_pos = targ_pos |> round(2),
           changes0 = (targ_pos - value),
           changes1 = if_else(abs(changes0)<sum(value)*min_change,0,changes0),
           changes = pmin(abs(changes1),sum(value)*max_change)*(changes1/abs(changes1))) |>
    select(-changes0, -changes1)
  
  # an algorithm that sorts by order of trades to make
  moneymarket <- joined |> filter(str_equal(Symbol,"SPAXX"))
  buys <- joined |> 
    filter(!str_equal(Symbol,"SPAXX"), changes > 0) |> 
    # mutate(changes = pmin(sum(joined$value) * max_change, changes)) |>
    arrange(desc(changes)) |>
    # filter(cumany(sum(changes)-cumsum(changes) > sum(moneymarket$value)))
    mutate(changes = if_else(cumsum(changes) < sum(moneymarket$value)*(1-sell_buffer), changes, pmax(0,sum(moneymarket$value)*(1-sell_buffer)-cumsum(changes)+changes) |> pmin(changes)))
  sells <- joined |> 
    filter(!str_equal(Symbol,"SPAXX"), changes < 0) |>
    # mutate(changes = pmax(-1 * sum(joined$value) * max_change, changes)) |> 
    arrange(changes) |>
    # filter(!cumall(-cumsum(changes) + sum(moneymarket$value) - sum(buys$changes) <= sum(moneymarket$targ_pos)))
    mutate(changes = if_else(-cumsum(changes) < sum(moneymarket$targ_pos), changes, pmin(0,-sum(moneymarket$targ_pos)-cumsum(changes)+changes) |> pmax(changes)))
  
  # print(buys)
  # print(sells)

  trades <- buys |>
    add_row(sells) |>
    arrange(desc(abs(changes)))
  
  holds <- joined |> 
    filter(not(Symbol %in% trades$Symbol),
           !str_equal(Symbol, "SPAXX")) |>
    mutate(changes = 0)
  
  prox <- add_row(trades, holds) |>
    mutate(changes = changes |> round_any(1))
  
  moneymarket |> dplyr::rows_update(tibble(Symbol = "SPAXX", changes = -sum(prox$changes))) |>
    add_row(prox, .before = 1) |>
    mutate(new_est = value + changes)
}
```


```{r calctrades, eval=FALSE}

## broken since I updated the fun

new_positions <- positions |> 
  filter(`Account Number` == accounts$`Account Number`[str_detect(accounts$`Account Name` |> str_to_lower(),"bda" |> str_to_lower())]) |>
  select(Symbol, value = `Current Value`) |>
  calc_trades(targets, cash_reserve = 0.1*2/3, max_change = 0.1, min_change = 0.005, transfer = 0) 

# new_positions |> summarise(total = sum(new_est))
new_positions


```

```{r historictrends, eval=FALSE}
  
hist <- download_paramaters$path |> read_csv(id = "path", col_types = "Ddddddd") |>
  na.omit() |>
  left_join(download_paramaters |> select(Symbol, path)) |>
  select(Symbol, !path) |>
  group_by(Symbol) |>
  mutate(Delta = `Adj Close` - lag(`Adj Close`, order_by = Date),
         pDelta = Delta/lag(`Adj Close`, order_by = Date),
         apyDelta = pDelta * dyears(1)/as.duration(interval(lag(Date, order_by = Date),Date)),
         dNow = apyDelta - last(apyDelta, order_by = `Date`)) |>
  arrange(desc(Date)) |>
  mutate(meanNagoAPYdelta = cummean(apyDelta)) |>
  filter(!is.na(Delta))

hist |>
  filter(as.duration(interval(Date, max(Date))) <= dyears(3)) |>
  summarise(mean(apyDelta),
            last(apyDelta, order_by = Date))

# FAMRX <- hist |> filter(str_equal(Symbol, "FAMRX"))
# lm(apyDelta ~ Date, FAMRX) |> anova()

hist |> 
  # filter(str_equal(Symbol, "FSELX")) |>
  filter(as.duration(interval(Date, max(Date))) <= dyears(3)) |>
ggplot(aes(x = Date, y = meanNagoAPYdelta, color = Symbol, fill = Symbol)) +
  geom_point(size = 1e-4, alpha = 3/4) +
  geom_smooth(method = "lm", alpha = 0.25) +
  facet_wrap(vars(Symbol)) +
  theme_minimal() 
  # theme(aspect.ratio = 1)

hist |> 
  # filter(str_equal(Symbol, "FAMRX")) |>
  # filter(as.duration(interval(Date, max(Date))) <= ddays(30)) |>
ggplot(aes(x = lag(apyDelta, n=1L, order_by = apyDelta), y = apyDelta, color = Symbol, fill = Symbol)) +
  geom_point(size = 1e0, alpha = 1) +
  geom_smooth(method = "lm", alpha = 0.25) +
  # facet_wrap(vars(Symbol)) +
  theme_minimal()

```


```{r forecasting2, eval=FALSE}
  
hist2 <- download_paramaters$path |> read_csv(id = "path", col_types = "Ddddddd") |>
  na.omit() |>
  left_join(download_paramaters |> select(Symbol, path)) |>
  select(Symbol, !path) |>
  filter(!is.na(`Adj Close`))
  
hist2 %<>% add_row(
  tibble(Symbol = "SPAXX",
       Date = unique(hist2$Date),
       Open = 1,
       High = 1,
       Low = 1,
       Close = 1,
       `Adj Close` = 1,
       Volume = 0))

hist2 %<>% group_by(Symbol)
# 
# hist2 %>% 
#   # filter(as.duration(interval(Date, max(Date))) <= dyears(1)) %>%
#   group_by(Symbol) %>%
#   summarise(lastObs = last(Date, order_by = Date),
#             lastClose = last(`Adj Close`, order_by = Date),
#             preditionDate = today(),
#             prediction = lm(`Adj Close` ~ Date + Symbol, data = .) |> predict(newdata = tibble(Date = preditionDate, Symbol) |> distinct()),
#             deviationFromPrediction = (lastClose - prediction)/prediction)


## TODO modify to calculate a long tern prediction and a short term predication. The short term may be based on 1 or a few days of data where the long term may be based on months or years. Basic idea is to make decisions by comparing the long and short term predications.

# test <- sapply(hist2$Symbol |> unique(), data = hist2, trunkateAt = dyears(1), predDate = today(), \(s,data,trunkateAt,predDate) {
#   data %<>% filter(as.duration(interval(Date, max(Date))) <= trunkateAt)
#   model <- lm(`Adj Close` ~ Date, data = filter(data, str_equal(Symbol,s)))
#   modelSummary <- model |> 
#     broom::tidy() |> 
#     mutate(Symbol = s, .before = 1) |> 
#     filter(term == "Date")
#   prediction <- model |> predict(newdata = tibble(Date = predDate))
#   predictionSummary <- modelSummary |> 
#     mutate(predictionDate = predDate,
#            prediction = prediction)
#   predictionSummary
#   }, simplify = F) |>
#   list_rbind()
  
# single core
predictPriceSummary_s <- function(data, range, new) {
  sapply(data$Symbol |> unique(), data = data, range = range, new = new, \(s,data,range,new) {
    data %<>% filter(as.duration(interval(Date, max(Date))) <= range)
    model <- lm(`Adj Close` ~ Date, data = filter(data, str_equal(Symbol,s)))
    modelSummary <- model |> 
      broom::tidy() |> 
      # filter(term == "Date")
      pivot_wider(names_from = "term", values_from = !term) |> 
      mutate(Symbol = s, .before = 1)
    prediction <- model |> predict(newdata = tibble(Date = new))
    predictionSummary <- modelSummary |> 
      mutate(predictionDate = new,
             prediction = prediction)
    predictionSummary
    }, simplify = F) |>
    list_rbind()
}

# multi-core
predictPriceSummary_p <- function(data, range, new) {
  parSapply(cl = getDefaultCluster(), data$Symbol |> unique(), data = data, range = range, new = new, FUN = \(s,data,range,new) {
    data <- data |> dplyr::filter(lubridate::as.duration(lubridate::interval(Date, max(Date))) <= range)
    model <- lm(`Adj Close` ~ Date, data = dplyr::filter(data, stringr::str_equal(Symbol,s)))
    modelSummary <- model |> 
      broom::tidy() |> 
      # filter(term == "Date")
      tidyr::pivot_wider(names_from = "term", values_from = !term) |> 
      dplyr::mutate(Symbol = s, .before = 1)
    prediction <- model |> predict(newdata = tibble::tibble(Date = new))
    predictionSummary <- modelSummary |> 
      dplyr::mutate(predictionDate = new,
             prediction = prediction)
    predictionSummary
    }, simplify = F) |>
    list_rbind()
}

predictPriceSummary <- function(data, range, new) if(length(unique(data$Symbol))*range/ddays(1) < 100) predictPriceSummary_s(data, range, new) else predictPriceSummary_p(data, range, new)

# lm(`Adj Close` ~ Date, data = filter(hist2, str_equal(Symbol,"FDSVX"))) |> 
#       broom::tidy() |> 
#       mutate(Symbol = "FDSVX", .before = 1) |> 
#       # filter(term == "Date")
#       pivot_wider(names_from = "term", values_from = !term)


longPred <- predictPriceSummary(hist2, dyears(2), nextTradingClose() |> as.Date()) |>
  rename_with(~ paste0(.x,"_long",recycle0 = TRUE), where(is.numeric))

midPred <- predictPriceSummary(hist2, dyears(.25), nextTradingClose() |> as.Date()) |>
  rename_with(~ paste0(.x,"_mid",recycle0 = TRUE), where(is.numeric))

shortPred <- predictPriceSummary(hist2, ddays(7), nextTradingClose() |> as.Date()) |>
  rename_with(~ paste0(.x,"_short",recycle0 = TRUE), where(is.numeric))

oppoPred <- full_join(longPred, midPred) |> full_join(shortPred) |>
  select(Symbol, predictionDate, starts_with("prediction_"), starts_with("estimate")) |>
  mutate(longOpporotunity = (prediction_long - prediction_short)/prediction_long,
         midOpporotunity = (prediction_mid - prediction_short)/prediction_mid,
         opporotunity = (longOpporotunity + midOpporotunity)/2,
         rank = rank(desc(opporotunity)),
         across(ends_with("pporotunity"),\(x) round_any(x, 10^round_any(log10(.0001/prediction_long),1))),
         Symbol = as.factor(Symbol),
         .after = 1) |>
  # mutate(round_tunity = round_any(opporotunity, 10^round_any(log10(.01/prediction_long),1))) |>
  arrange(rank)

```

```{r visualize, eval=FALSE}

# size <- 10*10^-((hist2$Symbol |> unique() |> length()) ^-1.5)

# tsize <- 20/((hist2$Symbol |> unique() |> length())^(.2))
# psize <- tsize / 5e1
# hist2 |> 
#   # filter(str_equal(Symbol,"FDSVX")) |>
#   filter(as.duration(interval(Date, max(Date))) <= dyears(1/12)) |>
#   ggplot(aes(x = Date, color = Symbol, fill = Symbol)) +
#   geom_point(aes(y = `Adj Close`),size = psize, alpha = 3/4) +
#   geom_point(aes(x = predictionDate, y = prediction_long, fill = NULL), data = oppoPred, shape = 24) +
#   geom_point(aes(x = predictionDate, y = prediction_short, fill = NULL), data = oppoPred, shape = 25) +
#   geom_abline(aes(slope = estimate_Date_long, intercept = `estimate_(Intercept)_long`, color = Symbol, fill = Symbol), data = oppoPred, linetype = "longdash", alpha = 2/4) +
#   geom_abline(aes(slope = estimate_Date_short, intercept = `estimate_(Intercept)_short`, color = Symbol, fill = Symbol), data = oppoPred, linetype = "dashed", alpha = 2/4) +
#   facet_wrap(vars(Symbol), scales = "free_y") +
#   theme_minimal() +
#   # ggpubr::clean_theme() +
#   theme(legend.position="none", text = element_text(size = tsize))


oppoPred_t12 <- oppoPred |> filter(rank <= 12)
tsize <- 20/((oppoPred_t12$Symbol |> unique() |> length())^(.2))
psize <- tsize / 5e1
hist2 |> 
  filter(Symbol %in% (oppoPred_t12 |> pull(Symbol))) |>
  filter(as.duration(interval(Date, max(Date))) <= dyears(1)) |>
  ggplot(aes(x = Date, color = Symbol, fill = Symbol)) +
  geom_point(aes(y = `Adj Close`),size = psize, alpha = 3/4) +
  geom_point(aes(x = predictionDate, y = prediction_long, fill = NULL), data = oppoPred_t12, shape = 24) +
  geom_point(aes(x = predictionDate, y = prediction_mid, fill = NULL), data = oppoPred_t12, shape = 23) +
  geom_point(aes(x = predictionDate, y = prediction_short, fill = NULL), data = oppoPred_t12, shape = 25) +
  geom_abline(aes(slope = estimate_Date_long, intercept = `estimate_(Intercept)_long`, color = Symbol, fill = Symbol), data = oppoPred_t12, linetype = "longdash", alpha = 2/4) +
  geom_abline(aes(slope = estimate_Date_mid, intercept = `estimate_(Intercept)_mid`, color = Symbol, fill = Symbol), data = oppoPred_t12, linetype = "dashed", alpha = 2/4) +
  geom_abline(aes(slope = estimate_Date_short, intercept = `estimate_(Intercept)_short`, color = Symbol, fill = Symbol), data = oppoPred_t12, linetype = "dotted", alpha = 2/4) +
  facet_wrap(vars(Symbol), scales = "free_y") +
  theme_minimal() +
  # ggpubr::clean_theme() +
  theme(legend.position="none", text = element_text(size = tsize))

```

```{r calctradesfun2}

##
# positions is tibble as downloaded from fidelity
# targets is tibble with symbols and target distributions


calc_trades_2 <- function(positions2, opporotunities, cash_reserve = 0.05, sell_buffer = 0.05, maxBuys = 2) {
  
  # joined <- full_join(positions,targets)
  
  joined <- full_join(positions2, opporotunities) |>
    mutate(value = if_else(is.na(value), 0, value))
  
  buyPotentials <- joined |> 
    filter(opporotunity >= 0) |>
    slice_max(order_by = opporotunity, n=maxBuys) |>
    mutate(proportion_1 = rescale(opporotunity, to = c(0, 1), range = c(0, max(opporotunity))),
           proportion = proportion_1/sum(proportion_1),
           buy = proportion * pull(filter(joined,str_equal(Symbol,"SPAXX")),value) * (1-sell_buffer))
  
  sellPotentials <- joined |>
    filter(value > 0,
           !str_equal(Symbol,"SPAXX")) |>
    mutate(relativeOpp = opporotunity - min(buyPotentials$opporotunity)) |>
    arrange(relativeOpp) |>
    filter(relativeOpp <= 0) |>
    # mutate(proportion_1 = value * rescale(relativeOpp, to = c(1,0)),
    #        proportion = proportion_1/sum(proportion_1),
    #        sell = proportion * sum(joined$value)*cash_reserve)
    mutate(proportion_1 = rescale(relativeOpp, to = c(1,0)),
           proportion = proportion_1/sum(proportion_1),
           sell = 0)
           # sell_0 = pmin(value,cumsum(proportion)*sum(joined$value)*cash_reserve))
           # sell_0 = proportion * sum(joined$value)*cash_reserve,
           # sell_1 = pmin(value,sell_0),
           # underage = sell_0-sell_1)
    # rowwise() |>
    # mutate(sell_0 = 0,
    #        sell_0 = cumsum(proportion)*sum(joined$value)*cash_reserve - cumsum(sell_0),
    #        sell_2 = min(value,proportion*sum(joined$value)*cash_reserve),
    #        underage = cumsum(proportion)*sum(joined$value)*cash_reserve - cumsum(sell_2),
    #        sell_3 = sell_2 + lag(underage))
    # mutate(sell_a = pmin(value, cumsum(proportion)*sum(joined$value)*cash_reserve),
    #        sell_b = sell_a - lag((sell_a), default = 0),
    #        sell_c = 0)
  
  
  ## TODO Fix
  while(sum(sellPotentials$sell) < min(sum(joined$value)*cash_reserve)) {
    sellPotentials |>
      mutate()
  }
  
  sum(joined$value)*cash_reserve-sellPotentials$sell |> sum()
  
  trades <- full_join(sellPotentials |> select(Symbol, sell),
                      buyPotentials |> select(Symbol, buy))
  
  out <- full_join(positions2, trades) |>
    mutate(across(where(is.numeric), as.double),
           across(where(is.numeric), \(x) if_else(is.na(x), 0, x |> round_any(1))),
           estNew = if_else(!str_equal(Symbol,"SPAXX"),value - sell + buy,value - sum(buy) + sum(sell))) |>
    arrange(desc(buy),desc(sell))
  out
  
  ## TODO re-add any with current value that may have been omitted from the trades table. 
  
}

positions2 <- positions |> 
  filter(`Account Number` == accounts$`Account Number`[str_detect(accounts$`Account Name` |> str_to_lower(),"bda" |> str_to_lower())]) |>
  select(Symbol, value = `Current Value`) |>
  rows_update(tibble_row(Symbol = "FPHAX", value = 200))

opporotunities <- oppoPred |> select(Symbol, opporotunity)

trades <- calc_trades_2(positions2, opporotunities, cash_reserve = 0.05, sell_buffer = 0.05, maxBuys = 4)

```

