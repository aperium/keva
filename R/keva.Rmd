---
title: An attempt at optimal allocation minimizing optorunity costs
author: Daniel R. Williams ^[Director of Quality Control, Greenstreet Growers, Lothian,
  MD] ^[PhD Candidate, Dept. of Ag. & Crop Science, Ohio State University, Columbus,  Ohio]
date: 7 Aug 2024
output:
  html_notebook: default
---

# To Do

- [ ] I/O functions
  - [ ] where/how best to pull data? `rest` or an api?
  - [ ] how best to manage data? local storage of downloaded data?
- [ ] Alogrithms
  - [ ] retrieve plan from previous projects
  - [ ] retrieve plan from Tim

```{r setup, echo=FALSE, error=TRUE, message=TRUE, warning=TRUE, include=FALSE}
# this block loads required packages and some custom functions. 
cran_pacs <- c("tidyverse","writexl","fs","stringr","rlang","magrittr","stats","foreach", "doParallel", "parallel", "fs", "janitor", "stringr","lubridate","forcats", "purrr","multidplyr", "curl", "units") #"rvest", "chromote","httr2", "forecast"
dev_pacs <- c() 
bioc_pacs <- c()
py_pacs <- c()

# install installers
if(length(find.package("pak", quiet = TRUE))==0) install.packages("pak")
if(length(find.package("librarian", quiet = TRUE))==0) pak::pak("librarian")
installer_pacs <- Filter(librarian::check_installed, c(if (length(bioc_pacs) > 0) "BiocManager", if (length(py_pacs) > 0) "reticulate"))
if (length(installer_pacs) > 0) pak::pak(installer_pacs, upgrade = TRUE)

# install and load R pacs
r_pacs <- c(cran_pacs,dev_pacs,bioc_pacs) |> unique()
if (length(r_pacs) > 0) {
  pak::pak(r_pacs, upgrade = FALSE, ask = FALSE)
  librarian::shelf(r_pacs)
}

# install python packs
if (length(py_pacs)>0) {
  if (!reticulate::py_available(initialize = TRUE)) reticulate::install_python()
  if (reticulate::py_available(initialize = TRUE)) reticulate::py_install(py_pacs)
}

## register cores for foreach/doParallel
n_cores <- parallel::detectCores()
# registerDoParallel(cores=n_cores)
# stopImplicitCluster()

# doParallel cluster
if(!is_null(getDefaultCluster())) stopCluster(getDefaultCluster())
makeCluster(n_cores-1) |> setDefaultCluster()
registerDoParallel(getDefaultCluster())

# dplyr cluster
if(exists("dCluster")) rm(dCluster)
dCluster <- new_cluster(n_cores-1)
cluster_library_quiety <- purrr::quietly(cluster_library)
# cluster_library_quiety(dCluster, loadedNamespaces())
cluster_library_quiety(dCluster, librarian::check_attached())
```

```{r utils}

round_any = function(x, accuracy, f=round){f(x/accuracy) * accuracy}

lastTradingClose <- function(dt = now()) {
  dt %<>% with_tz("America/New_York")
  h <- dt |> hour()
  beforeClosePenalty <- if_else(h < 16L, dhours(24-16+h), dhours(-16+h))
  dt <- dt - beforeClosePenalty
  wday <- dt |> wday(week_start = 1)
  weekendPenalty <- if_else(wday > 5L, ddays(wday - 5L), ddays(0))
  dt <- dt - weekendPenalty
  dt |> update(hours = 16L, minutes = 0L, seconds = 0L, week_start = 1)
}

nextTradingClose <- function(dt = now()) {
  dt %<>% with_tz("America/New_York")
  h <- dt |> hour()
  beforeCloseBoost <- if_else(h < 16L, dhours(16-h), dhours(24+16-h))
  dt <- dt + beforeCloseBoost
  wday <- dt |> wday(week_start = 1)
  weekendBoost <- if_else(wday > 5L, ddays(8L - wday), ddays(0))
  dt <- dt + weekendBoost
  dt |> update(hours = 16L, minutes = 0L, seconds = 0L, week_start = 1)
}


```

```{r paths}

data_path <- "Dropbox (Personal)/Projects/investing" |> fs::path_home()
hist_path <- "Dropbox (Personal)/Projects/investing/historic data" |> fs::path_home()

```


```{r currentdata}

# install_unit(c("USD", "dollar"))


# "https://digital.fidelity.com/ftgw/digital/portfolio/positions"

# account_nums <-  path(data_path,"fidelity_accountnums.tsv") |> 
#   read_csv(show_col_types = FALSE) |>
#   pull(`fidelity internal account number`)

positions <- data_path |> 
  dir_ls(regexp = "/Portfolio_Positions_.*\\.csv$") |>
  as_tibble_col() |>
  mutate(date = value |> str_extract(pattern = "(?<=/Portfolio_Positions_).*(?=\\.csv$)") |> mdy()) |>
  slice_max(date) |>
  pull(1) |>
  read_csv(show_col_types = FALSE) |>
  filter(!is.na(Symbol)) |>
  mutate(across(`Last Price`:`Average Cost Basis`,\(x) str_remove_all(x,"[\\+$%]*") |> as.numeric()),
         # across(contains("Percent"),\(x) x/100),
         across(contains("Percent"),\(x) set_units(x,"%")),
         # across(where(is.numeric)&!contains("Percent"),\(x) as_units(x, "USD")),
         Symbol = Symbol |> str_extract("[:alnum:]*"),
         across(c(`Account Number`, `Symbol`, `Type`), as_factor))


targets <- data_path |> 
  path("fidelity_targets_20240803.tsv") |> 
  read_tsv(show_col_types = FALSE) |>
  mutate(across(c(`Symbol`), as_factor))

accounts <- positions |> 
  group_by(`Account Number`, `Account Name`) |>
  summarise(`Current Value` = sum(`Current Value`))

```

```{r pullhistoricdata}

# "https://query1.finance.yahoo.com/v7/finance/download/FAMRX?period1=938179800&period2=1723135605&interval=1d&events=history&includeAdjustedClose=true"
# symbols <- c(targets$Symbol, positions$Symbol) |> unique() |> keep(\(x) !str_equal(x,"SPAXX"))

baseURL <- "https://query1.finance.yahoo.com/v7/finance/download/"
start_date <- "01-01-2010" |> dmy() |> as_datetime() |> as.integer()
end_date <- now() |> round_date() |> as.integer()
query <- str_c("?period1=",start_date,"&period2=",end_date,"&interval=1d&events=history&includeAdjustedClose=true")

download_paramaters <- add_row(targets |> select(Symbol), positions |> select(Symbol)) |>
  distinct() |>
  filter(!str_equal(Symbol,"SPAXX")) |>
  mutate(url_query = str_c(baseURL, Symbol |> str_to_lower(),query),
         file_dest = path(hist_path, Symbol |> str_c(".csv")),
         file_exists = file_dest |> file_exists(),
         file_dest |> file_info(),
         file_age = interval(modification_time, now()) |> as.duration())

download_details <- download_paramaters |>
  # filter((!file_exists) | (file_age > dhours(8)))
  filter((!file_exists) | (modification_time < lastTradingClose() + dhours(2)) | ((modification_time < lastTradingClose()) & (file_age > dminutes(6))))
if(nrow(download_details) |> as.logical()) {
  download_details %<>% mutate(multi_download(url_query, file_dest))
  download_paramaters %<>% left_join(download_details)
  }


```

```{r calctradesfun}
calc_trades <- function(positions, targets, cash_reserve = 0.05, max_change = 0.1, min_change = 0.001, sell_buffer = 0.05, transfer = 0) {
  
  # joined <- full_join(positions,targets)
  
  joined <- targets |>
    arrange(rank) |>
    mutate(series = sapply(0:(n()-1),\(x) (1-n()^(-1))^x), 
           targ_prop = series/sum(series) * (1-cash_reserve)) |>
    add_case(Symbol = "SPAXX", targ_prop = cash_reserve) |>
    full_join(positions) |>
    mutate(across(where(is.numeric),\(x) if_else(is.na(x),0,x))) |>
    mutate(value = value + if_else(str_equal(Symbol,"SPAXX"), transfer, 0),
           targ_pos = sum(value) * targ_prop,
           targ_pos = targ_pos |> round(2),
           changes0 = (targ_pos - value),
           changes1 = if_else(abs(changes0)<sum(value)*min_change,0,changes0),
           changes = pmin(abs(changes1),sum(value)*max_change)*(changes1/abs(changes1))) |>
    select(-changes0, -changes1)
  
  # an algorithm that sorts by order of trades to make
  moneymarket <- joined |> filter(str_equal(Symbol,"SPAXX"))
  buys <- joined |> 
    filter(!str_equal(Symbol,"SPAXX"), changes > 0) |> 
    # mutate(changes = pmin(sum(joined$value) * max_change, changes)) |>
    arrange(desc(changes)) |>
    # filter(cumany(sum(changes)-cumsum(changes) > sum(moneymarket$value)))
    mutate(changes = if_else(cumsum(changes) < sum(moneymarket$value)*(1-sell_buffer), changes, pmax(0,sum(moneymarket$value)*(1-sell_buffer)-cumsum(changes)+changes) |> pmin(changes)))
  sells <- joined |> 
    filter(!str_equal(Symbol,"SPAXX"), changes < 0) |>
    # mutate(changes = pmax(-1 * sum(joined$value) * max_change, changes)) |> 
    arrange(changes) |>
    # filter(!cumall(-cumsum(changes) + sum(moneymarket$value) - sum(buys$changes) <= sum(moneymarket$targ_pos)))
    mutate(changes = if_else(-cumsum(changes) < sum(moneymarket$targ_pos), changes, pmin(0,-sum(moneymarket$targ_pos)-cumsum(changes)+changes) |> pmax(changes)))
  
  # print(buys)
  # print(sells)

  trades <- buys |>
    add_row(sells) |>
    arrange(desc(abs(changes)))
  
  holds <- joined |> 
    filter(not(Symbol %in% trades$Symbol),
           !str_equal(Symbol, "SPAXX")) |>
    mutate(changes = 0)
  
  prox <- add_row(trades, holds) |>
    mutate(changes = changes |> round_any(1))
  
  moneymarket |> dplyr::rows_update(tibble(Symbol = "SPAXX", changes = -sum(prox$changes))) |>
    add_row(prox, .before = 1) |>
    mutate(new_est = value + changes)
}
```


```{r calctrades}

new_positions <- positions |> 
  filter(`Account Number` == accounts$`Account Number`[str_detect(accounts$`Account Name` |> str_to_lower(),"bda" |> str_to_lower())]) |>
  select(Symbol, value = `Current Value`) |>
  calc_trades(targets, cash_reserve = 0.1*2/3, max_change = 0.1, min_change = 0.005, transfer = 0) 

# new_positions |> summarise(total = sum(new_est))
new_positions


```

```{r historictrends, eval=FALSE}
  
hist <- download_paramaters$path |> read_csv(id = "path", col_types = "Ddddddd") |>
  na.omit() |>
  left_join(download_paramaters |> select(Symbol, path)) |>
  select(Symbol, !path) |>
  group_by(Symbol) |>
  mutate(Delta = `Adj Close` - lag(`Adj Close`, order_by = Date),
         pDelta = Delta/lag(`Adj Close`, order_by = Date),
         apyDelta = pDelta * dyears(1)/as.duration(interval(lag(Date, order_by = Date),Date)),
         dNow = apyDelta - last(apyDelta, order_by = `Date`)) |>
  arrange(desc(Date)) |>
  mutate(meanNagoAPYdelta = cummean(apyDelta)) |>
  filter(!is.na(Delta))

hist |>
  filter(as.duration(interval(Date, max(Date))) <= dyears(3)) |>
  summarise(mean(apyDelta),
            last(apyDelta, order_by = Date))

# FAMRX <- hist |> filter(str_equal(Symbol, "FAMRX"))
# lm(apyDelta ~ Date, FAMRX) |> anova()

hist |> 
  # filter(str_equal(Symbol, "FSELX")) |>
  filter(as.duration(interval(Date, max(Date))) <= dyears(3)) |>
ggplot(aes(x = Date, y = meanNagoAPYdelta, color = Symbol, fill = Symbol)) +
  geom_point(size = 1e-4, alpha = 3/4) +
  geom_smooth(method = "lm", alpha = 0.25) +
  facet_wrap(vars(Symbol)) +
  theme_minimal() 
  # theme(aspect.ratio = 1)

hist |> 
  # filter(str_equal(Symbol, "FAMRX")) |>
  # filter(as.duration(interval(Date, max(Date))) <= ddays(30)) |>
ggplot(aes(x = lag(apyDelta, n=1L, order_by = apyDelta), y = apyDelta, color = Symbol, fill = Symbol)) +
  geom_point(size = 1e0, alpha = 1) +
  geom_smooth(method = "lm", alpha = 0.25) +
  # facet_wrap(vars(Symbol)) +
  theme_minimal()

```


```{r forecasting2}
  
hist2 <- download_paramaters$path |> read_csv(id = "path", col_types = "Ddddddd") |>
  na.omit() |>
  left_join(download_paramaters |> select(Symbol, path)) |>
  select(Symbol, !path) |>
  filter(!is.na(`Adj Close`)) |>
  group_by(Symbol)
  

# 
# hist2 %>% 
#   # filter(as.duration(interval(Date, max(Date))) <= dyears(1)) %>%
#   group_by(Symbol) %>%
#   summarise(lastObs = last(Date, order_by = Date),
#             lastClose = last(`Adj Close`, order_by = Date),
#             preditionDate = today(),
#             prediction = lm(`Adj Close` ~ Date + Symbol, data = .) |> predict(newdata = tibble(Date = preditionDate, Symbol) |> distinct()),
#             deviationFromPrediction = (lastClose - prediction)/prediction)


## TODO modify to calculate a long tern prediction and a short term predication. The short term may be based on 1 or a few days of data where the long term may be based on months or years. Basic idea is to make decisions by comparing the long and short term predications.

# test <- sapply(hist2$Symbol |> unique(), data = hist2, trunkateAt = dyears(1), predDate = today(), \(s,data,trunkateAt,predDate) {
#   data %<>% filter(as.duration(interval(Date, max(Date))) <= trunkateAt)
#   model <- lm(`Adj Close` ~ Date, data = filter(data, str_equal(Symbol,s)))
#   modelSummary <- model |> 
#     broom::tidy() |> 
#     mutate(Symbol = s, .before = 1) |> 
#     filter(term == "Date")
#   prediction <- model |> predict(newdata = tibble(Date = predDate))
#   predictionSummary <- modelSummary |> 
#     mutate(predictionDate = predDate,
#            prediction = prediction)
#   predictionSummary
#   }, simplify = F) |>
#   list_rbind()
  

predictPriceSummary <- function(data, range, new) {
  sapply(data$Symbol |> unique(), data = data, range = range, new = new, \(s,data,range,new) {
    data %<>% filter(as.duration(interval(Date, max(Date))) <= range)
    model <- lm(`Adj Close` ~ Date, data = filter(data, str_equal(Symbol,s)))
    modelSummary <- model |> 
      broom::tidy() |> 
      mutate(Symbol = s, .before = 1) |> 
      filter(term == "Date")
    prediction <- model |> predict(newdata = tibble(Date = new))
    predictionSummary <- modelSummary |> 
      mutate(predictionDate = new,
             prediction = prediction)
    predictionSummary
    }, simplify = F) |>
    list_rbind()
}

longPred <- predictPriceSummary(hist2, dyears(1), nextTradingClose() |> as.Date()) |>
  rename_with(~ paste0(.x,"_long",recycle0 = TRUE), where(is.numeric))

shortPred <- predictPriceSummary(hist2, ddays(1), nextTradingClose() |> as.Date()) |>
  rename_with(~ paste0(.x,"_short",recycle0 = TRUE), where(is.numeric))

full_join(longPred,shortPred) |>
  select(Symbol, predictionDate, estimate_long, estimate_short, prediction_long, prediction_short) |>
  mutate(opporotunity = (prediction_long - prediction_short)/prediction_long,
         rank = rank(desc(opporotunity))) |>
  arrange(rank)

```


